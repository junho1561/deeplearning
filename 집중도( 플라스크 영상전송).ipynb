{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask # 플라스크 클래스 임포트\n",
    "from flask import request, redirect\n",
    "from flask import render_template, Response\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cx_Oracle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imutils\n",
    "import time\n",
    "import timeit\n",
    "import dlib, sys\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "from face_detector import get_face_detector, find_faces\n",
    "from face_landmarks import get_landmark_model, detect_marks\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "from threading import Thread\n",
    "from threading import Timer\n",
    "from check_cam_fps import check_fps\n",
    "import make_train_data as mtd\n",
    "import light_remover as lr\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return true if training is successful : True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [13/Nov/2020 17:21:20] \"\u001b[37mPOST /test HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "118.40.119.27 - - [13/Nov/2020 17:21:24] \"\u001b[37mGET /video_fa HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return true if training is successful : True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [13/Nov/2020 17:41:45] \"\u001b[37mPOST /test HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "118.40.119.27 - - [13/Nov/2020 17:41:49] \"\u001b[37mGET /video_fa HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__) # 내장변수 name을 이용해 서버를 구동시키는 객체 생성\n",
    "\n",
    "\n",
    "count = 0 # 10초마다 한번씩 세는데 자바단에서 주기로 세달라해서 지역변수를 세워 놓았다.\n",
    "############################################################################################################################\n",
    "# 디비 입력 함수\n",
    "####################################################################################################################################\n",
    "def insertC(t):\n",
    "    conn=cx_Oracle.connect(\"hr/hr@localhost:1521/xe\")\n",
    "    cursor=conn.cursor()\n",
    "    sql =\"insert into concentration values(:1,:2,:3)\"\n",
    "    cursor.execute(sql,t)\n",
    "    cursor.close()\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    \n",
    "# 집중도 실행 함수 스트리밍으로 보내주기 위해 함수에 담아 주었다.\n",
    "def con():\n",
    "#############################################################################################################################\n",
    "            # 눈\n",
    "##############################################################################################################################\n",
    "    def eye_aspect_ratio(eye) :\n",
    "        eA = dist.euclidean(eye[1], eye[5]) \n",
    "        eB = dist.euclidean(eye[2], eye[4]) \n",
    "        eC = dist.euclidean(eye[0], eye[3])\n",
    "        ear = (eA + eB) / (2.0 * eC) \n",
    "        return ear\n",
    "###########################################################################################################################################\n",
    "            # 입\n",
    "##########################################################################################################################################       \n",
    "    def yawn_ratio(mouth) : # 하품 계산하는 공식\n",
    "        mA = dist.euclidean(mouth[13], mouth[19]) # 세로 길이\n",
    "        mB = dist.euclidean(mouth[15], mouth[17]) # 세로 길이\n",
    "        mC = dist.euclidean(mouth[0], mouth[6]) # 가로 길이\n",
    "        mr = (mA + mB) / (2.0 * mC)\n",
    "        return mr \n",
    "############################################################################################################################################\n",
    "      # 고개돌리기\n",
    "############################################################################################################################################\n",
    "    def get_2d_points(frame, rotation_vector, translation_vector, camera_matrix, val):\n",
    "        \"\"\"Return the 3D points present as 2D for making annotation box\"\"\"\n",
    "        point_3d = []\n",
    "        dist_coeffs = np.zeros((4,1))\n",
    "        rear_size = val[0]\n",
    "        rear_depth = val[1]\n",
    "        point_3d.append((-rear_size, -rear_size, rear_depth))\n",
    "        point_3d.append((-rear_size, rear_size, rear_depth))\n",
    "        point_3d.append((rear_size, rear_size, rear_depth))\n",
    "        point_3d.append((rear_size, -rear_size, rear_depth))\n",
    "        point_3d.append((-rear_size, -rear_size, rear_depth))\n",
    "\n",
    "        front_size = val[2]\n",
    "        front_depth = val[3]\n",
    "        point_3d.append((-front_size, -front_size, front_depth))\n",
    "        point_3d.append((-front_size, front_size, front_depth))\n",
    "        point_3d.append((front_size, front_size, front_depth))\n",
    "        point_3d.append((front_size, -front_size, front_depth))\n",
    "        point_3d.append((-front_size, -front_size, front_depth))\n",
    "        point_3d = np.array(point_3d, dtype=np.float).reshape(-1, 3)\n",
    "\n",
    "        # Map to 2d img points\n",
    "        (point_2d, _) = cv2.projectPoints(point_3d,\n",
    "                                          rotation_vector,\n",
    "                                          translation_vector,\n",
    "                                          camera_matrix,\n",
    "                                          dist_coeffs)\n",
    "        point_2d = np.int32(point_2d.reshape(-1, 2))\n",
    "        return point_2d\n",
    "\n",
    "    \n",
    "    def head_pose_points(frame, rotation_vector, translation_vector, camera_matrix):\n",
    "        \"\"\"\n",
    "        Get the points to estimate head pose sideways    \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        frame : np.unit8\n",
    "            Original Image.\n",
    "        rotation_vector : Array of float64\n",
    "            Rotation Vector obtained from cv2.solvePnP\n",
    "        translation_vector : Array of float64\n",
    "            Translation Vector obtained from cv2.solvePnP\n",
    "        camera_matrix : Array of float64\n",
    "            The camera matrix\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (x, y) : tuple\n",
    "            Coordinates of line to estimate head pose\n",
    "\n",
    "        \"\"\"\n",
    "        rear_size = 1\n",
    "        rear_depth = 0\n",
    "        front_size = frame.shape[1]\n",
    "        front_depth = front_size*2\n",
    "        val = [rear_size, rear_depth, front_size, front_depth]\n",
    "        point_2d = get_2d_points(frame, rotation_vector, translation_vector, camera_matrix, val)\n",
    "        y = (point_2d[5] + point_2d[8])//2\n",
    "        x = point_2d[2]\n",
    "\n",
    "        return (x, y)\n",
    "\n",
    "############################################################################################\n",
    "            # 변수 코드\n",
    "############################################################################################\n",
    "    OPEN_EAR = 0\n",
    "    EAR_THRESH = 0 \n",
    "\n",
    "    RUNNING_TIME = 0 \n",
    "    PREV_TERM = 0 \n",
    "\n",
    "    np.random.seed(30)\n",
    "    power, nomal, short = mtd.start(25) \n",
    "    test_data = []\n",
    "    result_data = []\n",
    "    prev_time = 0\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector() \n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\") \n",
    "    \n",
    "    (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"] \n",
    "    (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "    (mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "\n",
    " ############################################################################################\n",
    "            # 스레드\n",
    " ############################################################################################\n",
    "    global both_ear_list\n",
    "    both_ear_list = []\n",
    "    both_ear=0\n",
    "    \n",
    "    minMax = MinMaxScaler()\n",
    "    mr_list = []\n",
    "    mr_scaled_list = []\n",
    "    \n",
    "    head_angle_list = []\n",
    "    \n",
    "    global Concentration\n",
    "    Concentration = []\n",
    "    count = 0\n",
    "    #global ctime\n",
    "    #ctime_list = []\n",
    "    #global ctime_result_list\n",
    "    #ctime_result_list=[]\n",
    "    #vtime = []\n",
    "    global cap\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    ret, frame = cap.read()\n",
    "    size = frame.shape\n",
    "    face_model = get_face_detector()\n",
    "    landmark_model = get_landmark_model()\n",
    "    pre_time = 0 \n",
    "\n",
    "    # 3D model points.\n",
    "    model_points = np.array([\n",
    "                                (0.0, 0.0, 0.0),             # Nose tip\n",
    "                                (0.0, -330.0, -65.0),        # Chin\n",
    "                                (-225.0, 170.0, -135.0),     # Left eye left corner\n",
    "                                (225.0, 170.0, -135.0),      # Right eye right corne\n",
    "                                (-150.0, -150.0, -125.0),    # Left Mouth corner\n",
    "                                (150.0, -150.0, -125.0)      # Right mouth corner\n",
    "                            ])\n",
    "\n",
    "    # Camera internals\n",
    "    focal_length = size[1]\n",
    "    center = (size[1]/2, size[0]/2)\n",
    "    camera_matrix = np.array(\n",
    "                             [[focal_length, 0, center[0]],\n",
    "                             [0, focal_length, center[1]],\n",
    "                             [0, 0, 1]], dtype = \"double\"\n",
    "                             )\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "       \n",
    "        ## 시간반복을 주기 위해\n",
    "        if pre_time == 0 :\n",
    "            pre_time = time.time()\n",
    "            \n",
    "        current_time = time.time()\n",
    "        \n",
    "        if not ret:\n",
    "            print('비디오 읽기 오류')\n",
    "            break\n",
    "        \n",
    "        frame = cv2.flip(frame,1)\n",
    "        frame = imutils.resize(frame, width = 400) # 이미지 크기재조정\n",
    "        L, gray = lr.light_removing(frame) # 조명 영향 최소화\n",
    "        \n",
    "        rects = detector(gray,0)\n",
    "        faces = find_faces(frame, face_model)\n",
    "        for face in faces:\n",
    "            marks = detect_marks(frame, landmark_model, face)\n",
    "            # mark_detector.draw_marks(frame, marks, color=(0, 255, 0))\n",
    "            image_points = np.array([\n",
    "                                    marks[30],     # Nose tip\n",
    "                                    marks[8],     # Chin\n",
    "                                    marks[36],     # Left eye left corner\n",
    "                                    marks[45],     # Right eye right corne\n",
    "                                    marks[48],     # Left Mouth corner\n",
    "                                    marks[54]      # Right mouth corner\n",
    "                                ], dtype=\"double\")\n",
    "            dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
    "            (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_UPNP)\n",
    "            \n",
    "            \n",
    "            # Project a 3D point (0, 0, 1000.0) onto the image plane.\n",
    "            # We use this to draw a line sticking out of the nose\n",
    "            \n",
    "            (nose_end_point2D, jacobian) = cv2.projectPoints(np.array([(0.0, 0.0, 1000.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
    "            \n",
    "            #for p in image_points:\n",
    "                #cv2.circle(frame, (int(p[0]), int(p[1])), 3, (0,0,255), -1)\n",
    "            \n",
    "            \n",
    "            p1 = ( int(image_points[0][0]), int(image_points[0][1]))\n",
    "            p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n",
    "            x1, x2 = head_pose_points(frame, rotation_vector, translation_vector, camera_matrix)\n",
    "\n",
    "            #cv2.line(frame, p1, p2, (0, 255, 255), 2)\n",
    "            #cv2.line(frame, tuple(x1), tuple(x2), (255, 255, 0), 2)\n",
    "            # for (x, y) in marks:\n",
    "            #     cv2.circle(img, (x, y), 4, (255, 255, 0), -1)\n",
    "            # cv2.putText(img, str(p1), p1, font, 1, (0, 255, 255), 1)\n",
    "            try:\n",
    "                m = (p2[1] - p1[1])/(p2[0] - p1[0])\n",
    "                ang = int(math.degrees(math.atan(m)))\n",
    "                head_angle_list.append(ang)\n",
    "            except:\n",
    "                ang = 90\n",
    "            cv2.putText(frame, \"HAG : {:.2f}\".format(ang), (280,60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,30,20), 2)\n",
    "        for rect in rects:\n",
    "            shape = predictor(gray, rect) #얼굴에서 랜드마크\n",
    "            shape = face_utils.shape_to_np(shape) # 68개의 점 좌표\n",
    "\n",
    "############################################################################################\n",
    "            # 눈 \n",
    " ############################################################################################\n",
    "            leftEye = shape[lStart:lEnd] #왼쪽 눈 점 좌표\n",
    "            rightEye = shape[rStart:rEnd]\n",
    "            leftEAR = eye_aspect_ratio(leftEye) #왼쪽 눈 평균거리\n",
    "            rightEAR = eye_aspect_ratio(rightEye)\n",
    "            \n",
    "            both_ear = (leftEAR + rightEAR) / 2  \n",
    "            \n",
    "            leftEyeHull = cv2.convexHull(leftEye)\n",
    "            rightEyeHull = cv2.convexHull(rightEye)\n",
    "            cv2.drawContours(frame, [leftEyeHull], -1, (0,255,0), 1) \n",
    "            cv2.drawContours(frame, [rightEyeHull], -1, (0,255,0), 1)\n",
    "                \n",
    "            mouth = shape[mStart:mEnd] # 입\n",
    "            mr = round(yawn_ratio(mouth), 2)   \n",
    "\n",
    "            cv2.putText(frame, \"EAR : {:.2f}\".format(both_ear), (280,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,30,20), 2)\n",
    "            both_ear_list.append(both_ear)\n",
    "            global eyes\n",
    "            \n",
    "            if(len(both_ear_list) >= 10):\n",
    "                both_ear_pd = pd.DataFrame(both_ear_list)\n",
    "                minMax.fit(both_ear_pd)\n",
    "                \n",
    "                eyes = minMax.transform(both_ear_pd)\n",
    "\n",
    "            \n",
    "############################################################################################\n",
    "            # 입\n",
    " ############################################################################################\n",
    "\n",
    "\n",
    "            mouthHull = cv2.convexHull(mouth)\n",
    "            cv2.drawContours(frame, [mouthHull], -1, (0,255,0), 1)\n",
    "\n",
    "            mr_list.append(mr)\n",
    "            \n",
    "            if len(mr_list)>=10:\n",
    "                df_mr_list = pd.DataFrame(mr_list)\n",
    "                minMax.fit(df_mr_list)\n",
    "                global df_mr_scaled\n",
    "                df_mr_scaled = minMax.transform(df_mr_list)\n",
    "\n",
    "            cv2.putText(frame, \"MAR : {:.2f}\".format(mr), (280,40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,30,20), 2)\n",
    "            \n",
    "            if(current_time - pre_time > 10.0):\n",
    "                if((len(both_ear_list) >= 10)):\n",
    "                    Concentration.append( ((0.6) * eyes[-1][0]) + ((0.2) * (1-(df_mr_scaled[-1][0]))) + ((0.2)*(1-math.cos(head_angle_list[-1]))) )\n",
    "                count += 1\n",
    "                pre_time = 0\n",
    "                #ctime_list.append(ctime)\n",
    "                #ctime_result_list.append(ctime_list[-1]-vtime[0])\n",
    "                #insertC((ctime_result_list[-1],Concentration [-1],myLecNo))\n",
    "                insertC((imyLecNo,count,Concentration[-1]))\n",
    "            cv2.putText(frame, \"MAR : {:.2f}\".format(mr), (280,40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,30,20), 2)\n",
    "            cv2.putText(frame, \"EAR : {:.2f}\".format(both_ear), (280,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,30,20), 2)\n",
    "            if(len(Concentration)>0):\n",
    "                cv2.putText(frame, \"CON : {:.2f}\".format(Concentration [-1]), (280,80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,30,20), 2)\n",
    "########################################################################################################\n",
    "        cv2.imshow(\"frame\",frame)\n",
    "        \n",
    "        ret, buffer = cv2.imencode('.jpg', frame)\n",
    "        frame = buffer.tobytes()\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')  \n",
    "      \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "@app.route('/test', methods=[\"GET\", \"POST\"])\n",
    "def test():\n",
    "    \n",
    "    if request.method == \"GET\":\n",
    "        myLecNo = request.args['myLecNo']\n",
    "    else:\n",
    "        myLecNo = request.form['myLecNo']\n",
    "    \n",
    "    global imyLecNo\n",
    "    imyLecNo = int(myLecNo)\n",
    "    \n",
    "    print(imyLecNo)\n",
    "  \n",
    "    resp = Response(myLecNo)\n",
    "    resp.headers['Access-Control-Allow-Origin'] = '*'\n",
    "    resp.headers['Access-Control-Allow-Methods'] = 'POST'\n",
    "    resp.headers['Access-Control-Allow-Headers'] = 'Origin'\n",
    "   \n",
    "    return resp\n",
    "            \n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/video_fa')\n",
    "def video_feed():\n",
    "    return Response(con(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host = '0.0.0.0',port = \"5000\", debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
